{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.llms import Ollama\n",
    "llm_routing=ChatGroq(groq_api_key=\"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\",model_name=\"Gemma2-9b-It\")\n",
    "llm_database = Ollama(base_url=\"http://10.75.22.61:11434\",model=\"gemma2:27b\")\n",
    "llm_vectorstore = Ollama(base_url=\"http://10.75.22.61:11434\",model=\"llama3.1:8b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['QdrantVectorStore', 'FastEmbedEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x0000021749E21A50>, search_kwargs={'k': 6})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model = FastEmbedEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\")\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=QdrantClient(host=\"localhost\", port=6333),\n",
    "    collection_name=\"SAS book\",\n",
    "    embedding=embedding_model,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an expert in SAS programming language\n",
    "Answer the following question based only on the provided context. \n",
    "Think step by step before providing a detailed answer. \n",
    "If you dont know the answer say that I don't know.\n",
    "I will tip you $1000 if the user finds the answer helpful. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "Question: {input}\"\"\")\n",
    "#from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "#document_chain= create_stuff_documents_chain(llm, prompt)\n",
    "retriever= vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAS (Statistical Analysis System) is a programming language used for data manipulation, analysis, and visualization. It is designed to perform statistical analysis, data mining, and business intelligence tasks. A SAS program consists of statements executed in order, with DATA steps creating SAS data sets and PROC steps analyzing or processing the data. The language also supports macros, which are reusable pieces of code that can be used to simplify complex programs. Overall, SAS is a powerful tool for working with data and performing statistical analysis.\n"
     ]
    }
   ],
   "source": [
    "system_template = \"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\n",
    "\"\"\"\n",
    "human_template = \"\"\"\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "system_message = SystemMessagePromptTemplate.from_template(template=system_template)\n",
    "human_message = HumanMessagePromptTemplate.from_template(template=human_template)\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    system_message, human_message\n",
    "])\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever , \"question\": RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | llm_vectorstore\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "ans=rag_chain.invoke(\"What is SAS programming language?\")\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='database'\n"
     ]
    }
   ],
   "source": [
    "### Router\n",
    "\n",
    "from typing import Literal\n",
    "# from langchain_cohere import ChatCohere\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "#from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "\n",
    "# Data model\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    datasource: Literal[\"vectorstore\", \"database\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to database or a vectorstore.\",\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "structured_llm_router = llm_routing.with_structured_output(RouteQuery)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are an expert at routing a user question to a vectorstore or database.\n",
    "The vectorstore contains documents related to SAS programming language and the database has information about different kind of IT assets.\n",
    "Use the vectorstore for questions on these topics. Otherwise, use database.\"\"\"\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_router = route_prompt | structured_llm_router\n",
    "print(\n",
    "    question_router.invoke(\n",
    "        {\"question\": \"How many assets are there?\"}\n",
    "    )\n",
    ")\n",
    "#print(question_router.invoke({\"question\": \"How many assets are there?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "mysql_uri = \"mysql+mysqlconnector://root:Pratap%408512@localhost:3306/medical_details\"\n",
    "db = SQLDatabase.from_uri(mysql_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"input\": \"How many employees are there in the database?\",\n",
    "        \"query\": \"SELECT COUNT(*) FROM employees;\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find all employees from the 'Marketing' department\",\n",
    "        \"query\": \"SELECT first_name, last_name, email, phone_number, hire_date, job_id, salary, manager_id, departments.department_name as DepartmentName FROM employees JOIN departments ON employees.department_id = departments.department_id WHERE departments.department_name = 'Marketing';\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Can you write a query to show department names and the average salary of employees in each department?\",\n",
    "        \"query\": \"\"\"SELECT departments.department_name, AVG(employees.salary) as AverageSalary\n",
    "                    FROM employees\n",
    "                    JOIN departments ON employees.department_id = departments.department_id\n",
    "                    GROUP BY departments.department_name;\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Which employee has the highest salary in the company?\",\n",
    "        \"query\": \"SELECT employees.first_name, employees.last_name, MAX(employees.salary) as MaxSalary FROM employees GROUP BY employees.first_name, employees.last_name;\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Find all employees from the 'Marketing' department\n",
      "SELECT first_name, last_name, email, phone_number, hire_date, job_id, salary, manager_id, departments.department_name as DepartmentName FROM employees JOIN departments ON employees.department_id = departments.department_id WHERE departments.department_name = 'Marketing';\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "# Create a formatter for the few shot templates\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"query\"], template=\"Question: {input}\\n{query}\"\n",
    ")\n",
    "\n",
    "print(example_prompt.format(**examples[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"\"\"\n",
    "You are a MySQL expert. Given an input question, first create a syntactically correct MySQL query to run.\n",
    "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use CURDATE() function to get the current date, if the question involves \"today\".\n",
    "Don't use ''' before the starting and ending of sql query.\n",
    "\n",
    "Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "{schema}\n",
    "\n",
    "\\nBelow are a number of examples of questions and their corresponding SQL queries.\n",
    "\"\"\",\n",
    "    suffix=\"\"\"For the below question, PROVIDE JUST THE SQL QUERY AND DO NOT PROVIDE ANY EXPLAINATION OR SUCH.\n",
    "    Question: {question}\\nSQL Query:\"\"\",\n",
    "    input_variables=[\"schema\", \"question\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_query_v2(prompt: PromptTemplate, db: SQLDatabase, question: str):\n",
    "    \"\"\"\n",
    "        Converts the user question to sql query.\n",
    "    \"\"\"\n",
    "    # Get the schema of the database\n",
    "    schema = db.get_context()['table_info']\n",
    "\n",
    "    # Generate the response from the LLM\n",
    "    chain: RunnableSequence = prompt | llm_database\n",
    "    response = chain.invoke(input={'schema': schema, 'question': question})\n",
    "    # print(f\"LLM Response: \\n{response}\\n\\n\")\n",
    "\n",
    "    # Extract the sql query from the response\n",
    "    # sql_query = extract_sql_query(llm_response=response)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def fetch_data_from_db(db: SQLDatabase, sql_query: str):\n",
    "    \"\"\"\n",
    "        Fetches the data by running the sql query on the database\n",
    "    \"\"\"\n",
    "    data = db.run(sql_query)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "template = \"\"\"\n",
    "Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Return the answer in the markdown format.\n",
    "Answer: \"\"\"\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(template=template)\n",
    "\n",
    "answer_chain: RunnableSequence = answer_prompt | llm_database | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT `name` FROM `hospital_details` WHERE `city` = 'New York'; \\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "user_question = \"Give the name of hospital in New York city\"\n",
    "\n",
    "# Getting the sql query\n",
    "sql_query = get_sql_query_v2(prompt=prompt, db=db, question=user_question)\n",
    "\n",
    "# Fetching the data from the databse using sql query\n",
    "response=sql_query\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: City Hospital \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_data = fetch_data_from_db(db=db, sql_query=response)\n",
    "# Final response\n",
    "response = answer_chain.invoke(input={\"question\": user_question, \"query\": sql_query, \"result\": sql_data})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## langraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = rag_chain.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def database(state):\n",
    "    \"\"\"\n",
    "    database search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with database results.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---database---\")\n",
    "    print(\"---HELLO--\")\n",
    "    question = state[\"question\"]\n",
    "    print(question)\n",
    "    sql_query = get_sql_query_v2(prompt=prompt, db=db, question= question)\n",
    "    response=sql_query\n",
    "    ans=sql_query.content\n",
    "    sql_data = fetch_data_from_db(db=db, sql_query=ans)\n",
    "    response = answer_chain.invoke(input={\"question\": question, \"query\": sql_query, \"result\": sql_data})\n",
    "\n",
    "    #return {\"documents\": docs, \"question\": question}\n",
    "    return {\"documents\": response, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to wiki search or RAG.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    if source.datasource == \"database\":\n",
    "        print(\"---ROUTE QUESTION TO database SEARCH---\")\n",
    "        return \"database\"\n",
    "    elif source.datasource == \"vectorstore\":\n",
    "        print(\"---ROUTE QUESTION TO RAG---\")\n",
    "        return \"vectorstore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "# Define the nodes\n",
    "workflow.add_node(\"database\", database)  # web search\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "\n",
    "# Build graph\n",
    "workflow.add_conditional_edges(\n",
    "    START,\n",
    "    route_question,\n",
    "    {\n",
    "        \"database\": \"database\",\n",
    "        \"vectorstore\": \"retrieve\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge( \"retrieve\", END)\n",
    "workflow.add_edge( \"database\", END)\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO RAG---\n",
      "---RETRIEVE---\n",
      "The SAS programming language is an interpreted multi-paradigm language designed for tasks such as data manipulation, statistical analysis, data visualization, and more. It consists of statements that communicate what you want to do and are written using the SAS language. A typical program starts with a DATA step to create a SAS data set and then passes the data to a PROC step for processing. The language is made up of two basic building blocks: DATA steps (which read and modify data) and PROC steps (which analyze data, perform utility functions, or print reports).'}'\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "inputs = {\n",
    "    \"question\": \"What is SAS programming language?\"  # What is SAS programming language? # Give no of tests which had status as normal.\n",
    "}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        #pprint(f\"Node '{value}':\")\n",
    "    #pprint(\"\\n---\\n\")\n",
    "        data= f\"Node '{value}':\"\n",
    "\n",
    "start = data.find(\"documents': '\") + len(\"documents': '\")\n",
    "end = data.find(\"',\", start)\n",
    "extracted_text = data[start:end]\n",
    "print(extracted_text)\n",
    "# Final generation\n",
    "#pprint(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
